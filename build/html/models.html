

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>models package &mdash; DAEMA 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> DAEMA
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">models package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-models.baseline_imputations">models.baseline_imputations module</a></li>
<li><a class="reference internal" href="#module-models.daema">models.daema module</a></li>
<li><a class="reference internal" href="#module-models.holoclean">models.holoclean module</a></li>
<li><a class="reference internal" href="#module-models.mida">models.mida module</a></li>
<li><a class="reference internal" href="#module-models.miss_forest">models.miss_forest module</a></li>
<li><a class="reference internal" href="#module-models">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">DAEMA</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>models package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="models-package">
<h1>models package<a class="headerlink" href="#models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-models.baseline_imputations">
<span id="models-baseline-imputations-module"></span><h2>models.baseline_imputations module<a class="headerlink" href="#module-models.baseline_imputations" title="Permalink to this headline">¶</a></h2>
<p>Basic imputation techniques.</p>
<dl class="py class">
<dt class="sig sig-object py" id="models.baseline_imputations.Identity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.baseline_imputations.</span></span><span class="sig-name descname"><span class="pre">Identity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.Identity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs identity (no imputation).</p>
<dl class="py method">
<dt class="sig sig-object py" id="models.baseline_imputations.Identity.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.Identity.test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.baseline_imputations.Identity.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.Identity.train_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.baseline_imputations.MeanImputation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.baseline_imputations.</span></span><span class="sig-name descname"><span class="pre">MeanImputation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.MeanImputation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#models.baseline_imputations.ValueImputation" title="models.baseline_imputations.ValueImputation"><code class="xref py py-class docutils literal notranslate"><span class="pre">models.baseline_imputations.ValueImputation</span></code></a></p>
<p>Performs mean imputation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="models.baseline_imputations.MeanImputation.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.MeanImputation.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.baseline_imputations.MeanImputation.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.MeanImputation.train_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.baseline_imputations.ValueImputation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.baseline_imputations.</span></span><span class="sig-name descname"><span class="pre">ValueImputation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.ValueImputation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Puts the same chosen value everywhere.</p>
<dl class="py method">
<dt class="sig sig-object py" id="models.baseline_imputations.ValueImputation.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.ValueImputation.test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.baseline_imputations.ValueImputation.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.baseline_imputations.ValueImputation.train_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.daema">
<span id="models-daema-module"></span><h2>models.daema module<a class="headerlink" href="#module-models.daema" title="Permalink to this headline">¶</a></h2>
<p>Model implementing the DAEMA paper</p>
<dl class="py class">
<dt class="sig sig-object py" id="models.daema.Daema">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.daema.</span></span><span class="sig-name descname"><span class="pre">Daema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.daema.Daema" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>DAEMA model as presented in the paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for initialisation</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="models.daema.Daema.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.daema.Daema.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Imputes the given samples using the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to impute</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>np.ndarray(Float); imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.daema.Daema.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.daema.Daema.train_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the network batch after batch as a generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for training</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
<li><p><strong>kwargs</strong> – keyword arguments to be passed to the Adam optimiser</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Integer; step number</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.daema.Generator">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.daema.</span></span><span class="sig-name descname"><span class="pre">Generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_cols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.daema.Generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Architecture of the DAEMA model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_cols</strong> – Int; number of columns in the dataset</p></li>
<li><p><strong>mask_input</strong> – Generator.FC, Generator.ELEMENTWISE or None; what input to use for the feature encoder
Generator.FC: Uses masks concatenated to the corresponding samples as input of the feature encoder
Generator.ELEMENTWISE: Uses masks to impute the samples with learned values
None: Uses only the samples as input of the feature encoder</p></li>
<li><p><strong>feature_size</strong> – (Int or None, Int or None) or None; (d’, d_z) from the paper ((ways, latent_dim))</p></li>
<li><p><strong>attention_mode</strong> – “classic”, “full”, “sep” or “no”; type of attention to use
full: as done in the paper, one set of weights per feature
classic: one set of weights for all features
sep: same as classic, but having d’ independent networks to produce each latent vector version
no: no attention at all (classical denoising autoencoder)</p></li>
<li><p><strong>activation</strong> – Str or None; torch.nn activation function to use at the end of the network
(or None for no activation)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="models.daema.Generator.ELEMENTWISE">
<span class="sig-name descname"><span class="pre">ELEMENTWISE</span></span><em class="property"> <span class="pre">=</span> <span class="pre">0</span></em><a class="headerlink" href="#models.daema.Generator.ELEMENTWISE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.daema.Generator.FC">
<span class="sig-name descname"><span class="pre">FC</span></span><em class="property"> <span class="pre">=</span> <span class="pre">1</span></em><a class="headerlink" href="#models.daema.Generator.FC" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.daema.Generator.MODES">
<span class="sig-name descname"><span class="pre">MODES</span></span><em class="property"> <span class="pre">=</span> <span class="pre">{1:</span> <span class="pre">'_FC',</span> <span class="pre">0:</span> <span class="pre">'_EW',</span> <span class="pre">None:</span> <span class="pre">'_NO'}</span></em><a class="headerlink" href="#models.daema.Generator.MODES" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.daema.Generator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.daema.Generator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – Tensor; samples with missing values</p></li>
<li><p><strong>masks</strong> – Tensor; corresponding masks</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor; imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.daema.Generator.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#models.daema.Generator.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.holoclean">
<span id="models-holoclean-module"></span><h2>models.holoclean module<a class="headerlink" href="#module-models.holoclean" title="Permalink to this headline">¶</a></h2>
<p>Contains the implementation of AimNet, from Holoclean.</p>
<dl class="py class">
<dt class="sig sig-object py" id="models.holoclean.AimNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.holoclean.</span></span><span class="sig-name descname"><span class="pre">AimNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_cols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_percent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.holoclean.AimNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>AimNet architecture as introduced in the AimNet paper (for numerical features only).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_size</strong> – Integer: size of the embeddings</p></li>
<li><p><strong>n_cols</strong> – Integer: number of features</p></li>
<li><p><strong>dropout_percent</strong> – proportion of values to drop during training</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="models.holoclean.AimNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.holoclean.AimNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>samples</strong> – Tensor; samples with missing values</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor; imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.holoclean.AimNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#models.holoclean.AimNet.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.holoclean.Holoclean">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.holoclean.</span></span><span class="sig-name descname"><span class="pre">Holoclean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.holoclean.Holoclean" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>AimNet procedure as introduced in the AimNet paper (for numerical features only).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for initialisation</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="models.holoclean.Holoclean.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.holoclean.Holoclean.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Imputes the given samples using the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to impute</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>np.ndarray(Float); imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.holoclean.Holoclean.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.holoclean.Holoclean.train_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the network epoch after epoch as a generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for training</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Integer; epoch number</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.mida">
<span id="models-mida-module"></span><h2>models.mida module<a class="headerlink" href="#module-models.mida" title="Permalink to this headline">¶</a></h2>
<p>Model implementing the MIDA paper, with some additional possibilities.</p>
<dl class="py class">
<dt class="sig sig-object py" id="models.mida.DAE">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.mida.</span></span><span class="sig-name descname"><span class="pre">DAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_cols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.mida.DAE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MIDA architecture as introduced in the MIDA paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_cols</strong> – Integer: number of features</p></li>
<li><p><strong>theta</strong> – Integer: hyperparameter to control the width of the network (see paper)</p></li>
<li><p><strong>depth</strong> – Integer: hyperparameter to control the depth of the network (see paper)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="models.mida.DAE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.mida.DAE.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>samples</strong> – Tensor; samples with missing values</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor; imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="models.mida.DAE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#models.mida.DAE.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.mida.MIDA">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.mida.</span></span><span class="sig-name descname"><span class="pre">MIDA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.mida.MIDA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>MIDA procedure as introduced in the MIDA paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for initialisation</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="models.mida.MIDA.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.mida.MIDA.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Imputes the given samples using the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to impute</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>np.ndarray(Float); imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.mida.MIDA.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.mida.MIDA.train_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the network batch after batch as a generator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for training</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
<li><p><strong>kwargs</strong> – keyword arguments to be passed to the Adam optimiser</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Integer; step number</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.miss_forest">
<span id="models-miss-forest-module"></span><h2>models.miss_forest module<a class="headerlink" href="#module-models.miss_forest" title="Permalink to this headline">¶</a></h2>
<p>MissForest model. The code for the MissForest comes mainly from missingpy:
<a class="reference external" href="https://github.com/epsilon-machine/missingpy/tree/master/missingpy">https://github.com/epsilon-machine/missingpy/tree/master/missingpy</a> , with some adjustments to make it compatible
with our pipeline.</p>
<dl class="py class">
<dt class="sig sig-object py" id="models.miss_forest.MissForest">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.miss_forest.</span></span><span class="sig-name descname"><span class="pre">MissForest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decreasing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">('mse',</span> <span class="pre">'gini')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForest" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Missing value imputation using Random Forests.</p>
<p>MissForest imputes missing values using Random Forests in an iterative
fashion. By default, the imputer begins imputing missing values of the
column (which is expected to be a variable) with the smallest number of
missing values – let’s call this the candidate column.
The first step involves filling any missing values of the remaining,
non-candidate, columns with an initial guess, which is the column mean for
columns representing numerical variables and the column mode for columns
representing categorical variables. After that, the imputer fits a random
forest model with the candidate column as the outcome variable and the
remaining columns as the predictors over all rows where the candidate
column values are not missing.
After the fit, the missing rows of the candidate column are
imputed using the prediction from the fitted Random Forest. The
rows of the non-candidate columns act as the input data for the fitted
model.
Following this, the imputer moves on to the next candidate column with the
second smallest number of missing values from among the non-candidate
columns in the first round. The process repeats itself for each column
with a missing value, possibly over multiple iterations or epochs for
each column, until the stopping criterion is met.
The stopping criterion is governed by the “difference” between the imputed
arrays over successive iterations. For numerical variables (<a href="#id1"><span class="problematic" id="id2">num_vars_</span></a>),
the difference is defined as follows:</p>
<blockquote>
<div><p>sum((X_new[:, <a href="#id3"><span class="problematic" id="id4">num_vars_</span></a>] - X_old[:, <a href="#id5"><span class="problematic" id="id6">num_vars_</span></a>]) ** 2) /
sum((X_new[:, <a href="#id7"><span class="problematic" id="id8">num_vars_</span></a>]) ** 2)</p>
</div></blockquote>
<p>For categorical variables(<a href="#id9"><span class="problematic" id="id10">cat_vars_</span></a>), the difference is defined as follows:</p>
<p>sum(X_new[:, <a href="#id11"><span class="problematic" id="id12">cat_vars_</span></a>] != X_old[:, <a href="#id13"><span class="problematic" id="id14">cat_vars_</span></a>])) / n_cat_missing</p>
<p>where X_new is the newly imputed array, X_old is the array imputed in the
previous round, n_cat_missing is the total number of categorical
values that are missing, and the sum() is performed both across rows
and columns. Following [1], the stopping criterion is considered to have
been met when difference between X_new and X_old increases for the first
time for both types of variables (if available).</p>
<p>NOTE: Most parameter definitions below are taken verbatim from the
Scikit-Learn documentation at [2] and [3].</p>
<dl>
<dt>max_iter<span class="classifier">int, optional (default = 10)</span></dt><dd><p>The maximum iterations of the imputation process. Each column with a
missing value is imputed exactly once in a given iteration.</p>
</dd>
<dt>decreasing<span class="classifier">boolean, optional (default = False)</span></dt><dd><p>If set to True, columns are sorted according to decreasing number of
missing values. In other words, imputation will move from imputing
columns with the largest number of missing values to columns with
fewest number of missing values.</p>
</dd>
<dt>missing_values<span class="classifier">np.nan, integer, optional (default = np.nan)</span></dt><dd><p>The placeholder for the missing values. All occurrences of
<cite>missing_values</cite> will be imputed.</p>
</dd>
<dt>copy<span class="classifier">boolean, optional (default = True)</span></dt><dd><p>If True, a copy of X will be created. If False, imputation will
be done in-place whenever possible.</p>
</dd>
<dt>criterion<span class="classifier">tuple, optional (default = (‘mse’, ‘gini’))</span></dt><dd><p>The function to measure the quality of a split.The first element of
the tuple is for the Random Forest Regressor (for imputing numerical
variables) while the second element is for the Random Forest
Classifier (for imputing categorical variables).</p>
</dd>
<dt>n_estimators<span class="classifier">integer, optional (default=100)</span></dt><dd><p>The number of trees in the forest.</p>
</dd>
<dt>max_depth<span class="classifier">integer or None, optional (default=None)</span></dt><dd><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</dd>
<dt>min_samples_split<span class="classifier">int, float, optional (default=2)</span></dt><dd><p>The minimum number of samples required to split an internal node:
- If int, then consider <cite>min_samples_split</cite> as the minimum number.
- If float, then <cite>min_samples_split</cite> is a fraction and</p>
<blockquote>
<div><p><cite>ceil(min_samples_split * n_samples)</cite> are the minimum
number of samples for each split.</p>
</div></blockquote>
</dd>
<dt>min_samples_leaf<span class="classifier">int, float, optional (default=1)</span></dt><dd><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.
- If int, then consider <cite>min_samples_leaf</cite> as the minimum number.
- If float, then <cite>min_samples_leaf</cite> is a fraction and</p>
<blockquote>
<div><p><cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum
number of samples for each node.</p>
</div></blockquote>
</dd>
<dt>min_weight_fraction_leaf<span class="classifier">float, optional (default=0.)</span></dt><dd><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</dd>
<dt>max_features<span class="classifier">int, float, string or None, optional (default=”auto”)</span></dt><dd><p>The number of features to consider when looking for the best split:
- If int, then consider <cite>max_features</cite> features at each split.
- If float, then <cite>max_features</cite> is a fraction and</p>
<blockquote>
<div><p><cite>int(max_features * n_features)</cite> features are considered at each
split.</p>
</div></blockquote>
<ul class="simple">
<li><p>If “auto”, then <cite>max_features=sqrt(n_features)</cite>.</p></li>
<li><p>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite> (same as “auto”).</p></li>
<li><p>If “log2”, then <cite>max_features=log2(n_features)</cite>.</p></li>
<li><p>If None, then <cite>max_features=n_features</cite>.</p></li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features.</p>
</dd>
<dt>max_leaf_nodes<span class="classifier">int or None, optional (default=None)</span></dt><dd><p>Grow trees with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</dd>
<dt>min_impurity_decrease<span class="classifier">float, optional (default=0.)</span></dt><dd><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.
The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.
<code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</dd>
<dt>bootstrap<span class="classifier">boolean, optional (default=True)</span></dt><dd><p>Whether bootstrap samples are used when building trees.</p>
</dd>
<dt>oob_score<span class="classifier">bool (default=False)</span></dt><dd><p>Whether to use out-of-bag samples to estimate
the generalization accuracy.</p>
</dd>
<dt>n_jobs<span class="classifier">int or None, optional (default=None)</span></dt><dd><p>The number of jobs to run in parallel for both <cite>fit</cite> and <cite>predict</cite>.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span>
for more details.</p>
</dd>
<dt>random_state<span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt><dd><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p>
</dd>
<dt>verbose<span class="classifier">int, optional (default=0)</span></dt><dd><p>Controls the verbosity when fitting and predicting.</p>
</dd>
<dt>warm_start<span class="classifier">bool, optional (default=False)</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See <span class="xref std std-term">the Glossary</span>.</p>
</dd>
<dt>class_weight<span class="classifier">dict, list of dicts, “balanced”, “balanced_subsample” or     None, optional (default=None)</span></dt><dd><p>Weights associated with classes in the form <code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>.
If not given, all classes are supposed to have weight one. For
multi-output problems, a list of dicts can be provided in the same
order as the columns of y.
Note that for multioutput (including multilabel) weights should be
defined for each class of every column in its own dict. For example,
for four-class multilabel classification weights should be
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of
[{1:1}, {2:5}, {3:1}, {4:1}].
The “balanced” mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>
The “balanced_subsample” mode is the same as “balanced” except that
weights are computed based on the bootstrap sample for every tree
grown.
For multi-output, the weights of each column of y will be multiplied.
Note that these weights will be multiplied with sample_weight (passed
through the fit method) if sample_weight is specified.
NOTE: This parameter is only applicable for Random Forest Classifier
objects (i.e., for categorical variables).</p>
</dd>
</dl>
<dl class="simple">
<dt><a href="#id15"><span class="problematic" id="id16">statistics_</span></a><span class="classifier">Dictionary of length two</span></dt><dd><p>The first element is an array with the mean of each numerical feature
being imputed while the second element is an array of modes of
categorical features being imputed (if available, otherwise it
will be None).</p>
</dd>
</dl>
<ul class="simple">
<li><p>[1] Stekhoven, Daniel J., and Peter Bühlmann. “MissForest—non-parametric
missing value imputation for mixed-type data.” Bioinformatics 28.1
(2011): 112-118.</p></li>
<li><p>[2] <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble</a>.
RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor</p></li>
<li><p>[3] <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble</a>.
RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">missingpy</span> <span class="kn">import</span> <span class="n">MissForest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nan</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;NaN&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">nan</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="n">nan</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">imputer</span> <span class="o">=</span> <span class="n">MissForest</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1337</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">Iteration: 0</span>
<span class="go">Iteration: 1</span>
<span class="go">Iteration: 2</span>
<span class="go">array([[1.  , 2. , 3.92 ],</span>
<span class="go">       [3.  , 4. , 3. ],</span>
<span class="go">       [2.71, 6. , 5. ],</span>
<span class="go">       [8.  , 8. , 7. ]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="models.miss_forest.MissForest.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForest.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the imputer on X.</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like}, shape (n_samples, n_features)</span></dt><dd><p>Input data, where <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> is the number of samples and
<code class="docutils literal notranslate"><span class="pre">n_features</span></code> is the number of features.</p>
</dd>
<dt>cat_vars<span class="classifier">int or array of ints, optional (default = None)</span></dt><dd><p>An int or an array containing column indices of categorical
variable(s)/feature(s) present in the dataset X.
<code class="docutils literal notranslate"><span class="pre">None</span></code> if there are no categorical variables in the dataset.</p>
</dd>
</dl>
<dl class="simple">
<dt>self<span class="classifier">object</span></dt><dd><p>Returns self.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.miss_forest.MissForest.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForest.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit MissForest and impute all missing values in X.</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like}, shape (n_samples, n_features)</span></dt><dd><p>Input data, where <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> is the number of samples and
<code class="docutils literal notranslate"><span class="pre">n_features</span></code> is the number of features.</p>
</dd>
</dl>
<dl class="simple">
<dt>X<span class="classifier">{array-like}, shape (n_samples, n_features)</span></dt><dd><p>Returns imputed dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.miss_forest.MissForest.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForest.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Impute all missing values in X.</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like}, shape = [n_samples, n_features]</span></dt><dd><p>The input data to complete.</p>
</dd>
</dl>
<dl class="simple">
<dt>X<span class="classifier">{array-like}, shape = [n_samples, n_features]</span></dt><dd><p>The imputed dataset.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="models.miss_forest.MissForestImpute">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">models.miss_forest.</span></span><span class="sig-name descname"><span class="pre">MissForestImpute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForestImpute" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>MissForest procedure as introduced in the MissForest paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for initialisation</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
<li><p><strong>kwargs</strong> – keyword arguments to be passed to the MissForest class</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="models.miss_forest.MissForestImpute.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForestImpute.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Imputes the given samples using the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to impute</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>np.ndarray(Float); imputed samples</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="models.miss_forest.MissForestImpute.train_generator">
<span class="sig-name descname"><span class="pre">train_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#models.miss_forest.MissForestImpute.train_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Stores the training samples to use these when test samples are to be imputed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – np.ndarray(Float); samples to use for training</p></li>
<li><p><strong>masks</strong> – np.ndarray(Float); corresponding mask matrix</p></li>
<li><p><strong>args</strong> – ArgumentParser; arguments of the program</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Integer; step number</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-models" title="Permalink to this headline">¶</a></h2>
<p>Contains all the models that can be used to impute missing data.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Simon Tihon, Muhammad Usama Javaid, Damien Fourure, Nicolas Posocco, Thomas Peel.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>